import { useState } from 'react';
import { useSearchParams } from 'next/navigation';
import { nanoid } from 'nanoid';
import { useFlowStore } from '@/store/flowStore';
import { chatHistoryAPI } from '@/services/chatHistoryAPI';
import { quotaService } from '@/services/quotaService';
import { authService } from '@/services/authService';
import { extractOutputFromContext, extractTextFromUpstream } from '@/store/executors/contextUtils';
import { showWarning } from '@/utils/errorNotify';
import { useChatSession } from './useChatSession';
import type { AppNode } from '@/types/flow';

// ============ Constants ============
const MESSAGES = {
    ERROR_EXECUTION: "ç”»å¸ƒå·¥ä½œæµå‡ºé”™",
    EMPTY_OUTPUT: "å·¥ä½œæµå·²å®Œæˆï¼Œä½†æœªç”Ÿæˆè¾“å‡ºã€‚",
} as const;

interface UseFlowChatProps {
    flowId: string | null;
}

export function useFlowChat({ flowId }: UseFlowChatProps) {
    const searchParams = useSearchParams();

    // Store Actions
    const runFlow = useFlowStore((s) => s.runFlow);
    const updateNodeData = useFlowStore((s) => s.updateNodeData);
    const nodes = useFlowStore((s) => s.nodes);

    // Streaming state from store
    const streamingText = useFlowStore((s) => s.streamingText);
    const streamingReasoning = useFlowStore((s) => s.streamingReasoning);
    const isStreaming = useFlowStore((s) => s.isStreaming);
    const isStreamingReasoning = useFlowStore((s) => s.isStreamingReasoning);

    // Derived Logic
    const {
        messages,
        setMessages,
        isLoading,
        setIsLoading,
        currentSessionId,
        setCurrentSessionId,
        refreshTrigger,
        setRefreshTrigger,
        loadSession,
        startNewSession,
        sessionCacheRef,
        activeSessionIdRef,
        updateSessionCache
    } = useChatSession({ flowId });

    // Local UI State
    const [input, setInput] = useState("");

    // ============ Helpers ============


    // ============ Actions ============
    const sendMessage = async (files?: File[]) => {
        // RACE CONDITION FIX: ç«‹å³æ¸…é™¤æ—§çš„æµå¼çŠ¶æ€
        // WHY: é˜²æ­¢æ—§çš„ streamingText åœ¨ useMemo ä¸­è¢«è¯†åˆ«ä¸ºæ–°çš„ AI å›å¤
        // TIMING: å¿…é¡»åœ¨ setIsLoading(true) å’Œæ·»åŠ æ–°æ¶ˆæ¯åˆ° messages ä¹‹å‰è°ƒç”¨
        // å¦åˆ™ page.tsx ä¸­çš„ useMemo ä¼šå°†æ—§çš„ streamingText æ˜¾ç¤ºä¸ºæ–°å›å¤
        useFlowStore.getState().clearStreaming();

        // 1. Validate Input
        const inputNodes = nodes.filter(n => n.type === "input");
        const inputNode = inputNodes[0];
        const inputNodeData = inputNode?.data as import("@/types/flow").InputNodeData | undefined;
        const enableTextInput = inputNodeData?.enableTextInput !== false;
        const enableFileInput = inputNodeData?.enableFileInput === true;
        const enableStructuredForm = inputNodeData?.enableStructuredForm === true;

        const hasText = input.trim().length > 0;
        const hasFiles = (files?.length ?? 0) > 0;
        const hasFormData = enableStructuredForm && inputNodeData?.formFields?.length;

        // ç»Ÿä¸€éªŒè¯ï¼šæ ¹æ®å¯ç”¨çš„æ¨¡å¼åˆ¤æ–­æ˜¯å¦å¯å‘é€
        const hasValidContent =
            (enableTextInput && hasText) ||
            (enableFileInput && hasFiles) ||
            (enableStructuredForm && hasFormData);
        if (!hasValidContent) return;
        if (isLoading || !flowId) return;

        let currentUser: any = null;

        // 2. Validate Quota
        try {
            currentUser = await authService.getCurrentUser();
            if (!currentUser) {
                setMessages(prev => [...prev, { role: "assistant", content: "è¯·å…ˆç™»å½•ä»¥ä½¿ç”¨ APP åŠŸèƒ½ã€‚", timestamp: new Date() }]);
                return;
            }

            const quotaCheck = await quotaService.checkQuota(currentUser.id, "app_usages");
            if (!quotaCheck.allowed) {
                setMessages(prev => [...prev, {
                    role: "assistant",
                    content: `æ‚¨çš„ APP ä½¿ç”¨æ¬¡æ•°å·²ç”¨å®Œ (${quotaCheck.used}/${quotaCheck.limit})ã€‚è¯·è”ç³»ç®¡ç†å‘˜å¢åŠ é…é¢ä»¥ç»§ç»­ä½¿ç”¨ã€‚`,
                    timestamp: new Date()
                }]);
                return;
            }
        } catch (e) {
            console.error("[useFlowChat] Quota check failed:", e);
            setMessages(prev => [...prev, { role: "assistant", content: "é…é¢æ£€æŸ¥å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚", timestamp: new Date() }]);
            return;
        }

        // 3. Prepare Session
        const userMsg = hasText ? input : "ğŸ“‹ å·²é€šè¿‡è¡¨å•æäº¤ä¿¡æ¯";
        let activeSessionId = currentSessionId;

        if (!activeSessionId) {
            activeSessionId = nanoid();
            window.history.replaceState(null, '', `/app?flowId=${flowId}&chatId=${activeSessionId}`);
            setCurrentSessionId(activeSessionId);
            activeSessionIdRef.current = activeSessionId;
        }

        // 4. Optimistic Update
        const newMessages = [
            ...messages,
            {
                role: "user" as const,
                content: userMsg,
                files: files // ä¿å­˜åŸå§‹æ–‡ä»¶å¯¹è±¡ä»¥ä¾¿ç«‹å³æ˜¾ç¤º
            }
        ];
        setMessages(newMessages);
        setInput("");
        setIsLoading(true);

        updateSessionCache(activeSessionId, newMessages, true);

        let currentMessageId: string | null = null;

        try {
            // 6. Handle File Uploads (if any)
            let uploadedFiles: any[] = [];
            if (hasFiles && inputNode) {
                const { fileUploadService } = await import("@/services/fileUploadService");
                const uploadPromises = files!.map(file =>
                    fileUploadService.completeUpload(file, inputNode.id, flowId, currentUser?.id)
                );
                const results = await Promise.all(uploadPromises);
                uploadedFiles = results.filter(f => f !== null);

                // æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ä¸Šä¼ å¤±è´¥
                const failedCount = files!.length - uploadedFiles.length;
                if (failedCount > 0) {
                    showWarning(
                        "éƒ¨åˆ†æ–‡ä»¶ä¸Šä¼ å¤±è´¥",
                        `${failedCount} ä¸ªæ–‡ä»¶æœªèƒ½ä¸Šä¼ ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•`
                    );
                }
            }

            // 5. Persist User Message (Now with uploaded attachments)
            const chatRecord = await chatHistoryAPI.addMessage(flowId, userMsg, activeSessionId, null, uploadedFiles.length > 0 ? uploadedFiles : null);
            if (activeSessionIdRef.current !== activeSessionId) return;

            if (chatRecord) {
                currentMessageId = chatRecord.id;
                setRefreshTrigger(prev => prev + 1);
            }

            // 7. Update Inputs & Run Flow
            if (inputNodes.length > 0) {
                for (const n of inputNodes) {
                    const nodeData = n.data as import("@/types/flow").InputNodeData;
                    // ä¼ é€’ formDataï¼ˆå¦‚æœå¯ç”¨äº†ç»“æ„åŒ–è¡¨å•ï¼‰å’Œå·²ä¸Šä¼ çš„æ–‡ä»¶
                    updateNodeData(n.id, {
                        text: userMsg,
                        formData: nodeData?.formData,
                        files: uploadedFiles.length > 0 ? uploadedFiles : undefined
                    });
                }
            }

            await runFlow(activeSessionId);
            if (activeSessionIdRef.current !== activeSessionId) return;

            // 8. Handle Result
            const freshState = useFlowStore.getState();
            let responseText = "";
            let responseAttachments: import("@/components/apps/FlowAppInterface/constants").Attachment[] = [];
            // Check Output Node mode to determine if we should show reasoning
            const outputNode = freshState.nodes.find(n => n.type === 'output');
            const outputMode = (outputNode?.data as any)?.inputMappings?.mode || 'direct';
            // Only show reasoning in direct or select modes
            const shouldShowReasoning = outputMode === 'direct' || outputMode === 'select';

            const responseReasoning = shouldShowReasoning ? (freshState.streamingReasoning || null) : null;
            let tokenUsage: { prompt_tokens: number; completion_tokens: number; total_tokens: number } | null = null;

            if (freshState.executionStatus === "completed") {
                const output = extractOutputFromContext(freshState.nodes, freshState.flowContext);
                responseText = output.text;
                responseAttachments = output.attachments;

                // NOTE: Reasoning ç°åœ¨éœ€è¦åœ¨ Output èŠ‚ç‚¹æ¨¡æ¿ä¸­æ˜¾å¼å¼•ç”¨ {{èŠ‚ç‚¹.reasoning}}
                // ä¸å†è‡ªåŠ¨ä» flowContext æå–

                // Extract token usage from LLM nodes in context
                for (const [nodeId, nodeOutput] of Object.entries(freshState.flowContext)) {
                    if (nodeId.startsWith('_')) continue;
                    const data = nodeOutput as Record<string, unknown>;
                    if (data?.usage && typeof data.usage === 'object') {
                        tokenUsage = data.usage as { prompt_tokens: number; completion_tokens: number; total_tokens: number };
                    }
                }
            } else {
                responseText = MESSAGES.ERROR_EXECUTION;
            }

            // 9. Persist AI Response FIRST (with retry) - before updating UI
            if (currentMessageId) {
                const maxRetries = 2;
                let persistSuccess = false;
                for (let attempt = 0; attempt <= maxRetries; attempt++) {
                    const success = await chatHistoryAPI.updateAssistantMessage(
                        currentMessageId,
                        responseText,
                        responseAttachments,
                        responseReasoning,
                        tokenUsage
                    );
                    if (success) {
                        persistSuccess = true;
                        break;
                    }
                    if (attempt < maxRetries) {
                        await new Promise(r => setTimeout(r, 1000 * (attempt + 1)));
                    }
                }
                if (!persistSuccess) {
                    showWarning("å›å¤ä¿å­˜å¤±è´¥", "AIå›å¤æœªèƒ½ä¿å­˜åˆ°æœåŠ¡å™¨ï¼Œåˆ·æ–°åå¯èƒ½ä¸¢å¤±");
                }
            }

            // 10. Update UI (after persistence to ensure data consistency)
            useFlowStore.getState().clearStreaming();
            setIsLoading(false);

            if (activeSessionIdRef.current !== activeSessionId) return;

            const updatedMessages = [
                ...newMessages,
                {
                    role: "assistant" as const,
                    content: responseText,
                    attachments: responseAttachments,
                    reasoning: responseReasoning || undefined,
                    timestamp: new Date()
                }
            ];
            setMessages(updatedMessages);
            updateSessionCache(activeSessionId, updatedMessages, false);

            // 11. Increment Quota (async, non-blocking)
            try {
                if (currentUser) {
                    await quotaService.incrementUsage(currentUser.id, "app_usages");
                    const { refreshQuota } = await import("@/store/quotaStore").then(m => m.useQuotaStore.getState());
                    await refreshQuota(currentUser.id);
                }
            } catch (e) {
                console.error("Quota increment failed:", e);
            }

        } catch (error) {
            console.error("Critical error in sendMessage:", error);
            if (activeSessionIdRef.current === activeSessionId) {
                useFlowStore.getState().clearStreaming();
                setIsLoading(false);
                setMessages(prev => [...prev, { role: "assistant", content: MESSAGES.ERROR_EXECUTION, timestamp: new Date() }]);
            }
        } finally {
            if (activeSessionIdRef.current === activeSessionId) {
                setRefreshTrigger(prev => prev + 1);
            }
        }
    };

    return {
        messages,
        input,
        setInput,
        isLoading,
        currentSessionId,
        refreshTrigger,
        loadSession,
        startNewSession,
        sendMessage,
        streamingText,
        streamingReasoning,
        isStreaming,
        isStreamingReasoning,
    };
}
